# go视频面试题

### 1.进程，线程和go程的关系

​      进程，“程序执行的一个实例” ，担当分配系统资源的实体。进程创建必须分配一个完整的独立地址空间。
​      线程 ，无独立的地址空间，有独立的PCB，最小的执行单位
​      协程，轻量级线程，多个协程分享该线程分配到的计算机资源。(cpu切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程一旦多起来，cpu调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不会那么像进程切换那么耗费资源。)



### 2.上下文切换指的是什么?

上下文切换就是先把前一个任务的CPU上下文(也就是CPU寄存器和程序计数器)保存起来，然后加载新任务的上下文，到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

简单说就是程序运行所需要的资源切换。



### 3.go的调度模型 MPG模型

Go的调度器内部有三个重要的结构：M，P，G

M：系统线程（物理线程），真正执行的执行单位

P：逻辑线程，可以将P抽象为者协程执行所需要的一个上下文或者资源，可以通过runtime.GOMAXPROCS(逻辑cpu核心数)

G：goroutine，有自己的栈，用于被调度

一个M都拥有一个P，每一个P也都有一个正在运行的goroutine。 P的数量可以通过GOMAXPROCS()来设置，它其实也就代表了真正的并发度，即有多少个goroutine可以同时运行。 

还有一些goroutine并没有运行，而是处于ready的就绪态，正在等待被调度。P维护着这个队列 

比如当一个OS线程M0陷入阻塞时，P转而在运行M1，的M1可能是正被创建，或者从线程缓存中取出。 

当M0返回时，它必须尝试取得一个P来运行goroutine，一般情况下，它会从其他的OS线程那里拿一个P过来， 若是没有拿到，这个M0这回把这个goroutine放到一个全局的 队列中（ global runqueue中），然后自己休眠放入线程缓存池中，所有P会定时轮询global runqueue并运行goroutine。

另外一种情况是由于P所分配到的G不均匀，某些P很快的就执行完他队列上的G，然后global runqueue又没有可执行的G，此时这些P就会从其他P上拿去G，一般run queue 的一半，保证每个os线程都能充分利用。



### 4.go struct能不能比较

如果结构体的所有成员变量都是可比较的，那么结构体就可比较

如果结构体中存在不可比较的成员变量，那么结构体就不能比较( slice，map，functions 这三个类型不能比较)

结构体之间进行转换需要他们具备完全相同的成员(字段名、字段类型、字段个数)

切片和map是不能比较的

另外map的key的数据类型是要能比较的



### 5.如何停止一个goroutine

解释

1.Context 包提供上下文机制在 goroutine 之间传递 deadline信号、cancel信号（cancellation signals）或者其他请求相关的信息。

业务场景

2.服务器通常要为每个 HTTP 请求创建一个 goroutine 以并发地处理业务。同时，这个 goroutine 也可能会创建更多的 goroutine 来访问数据库或者 RPC 服务。
当这个请求超时或者被终止的时候，context包可以优雅地退出所有衍生的 goroutine，并释放资源。还可以在goroutine以及其衍生goroutine之间传递信息，可以是 user 信息、认证 token等。

3.附加内容:

Context终止goroutine  一般配合 select 监听 `<-ctx.Done()`判断是否要结束，如果接受到值的话，就可以返回结束 goroutine 了；如果接收不到，就会继续进行运行任务。

### 6.如何打印当前go程id

runtime.Stack



### 7.map如何顺序读取

将map的key值存储到一个slice数组中，然后对数组进行排序，这样就可以通过slice数组里的值顺序去读map。



### 8.如何快速删除Slice中的一个元素

将最后一个元素赋值给待删除的元素，删除最后一个元素



### 9.在高并发场景下，为了实现对象的重用和减少GC压力，该怎么做？(比如zap日志框架为什么比其他日志框架快)

sync.pool



### 为什么是三次握手建立TCP连接，为什么是四次挥手断开连接

1.为什么是三次握手？

如果是两次握手，client 发送syn ，server端收到syn并发送ack 和 syn这样就建立连接 只能证明服务端有接收和发送的能力，client只证明了自己有发送能力，没有证明自己接收能力。四次握手就浪费了，三次能解决的事情，花了两次

为什么要是四次挥手，

四次挥手和三次握手的区别主要在 

四次挥手 中被动方，会先发送ack ，然后再发送fin，而不是ack和fin一起发送到主动断开连接方，这是因为断开连接是主动发起方不需要给server传输数据了，但是不能证明server也不用发送消息给主动方，所以这里不能马上发送fin，

【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？

答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。



### 乐观锁和悲观锁的使用场景

* 悲观锁:操作数据的时候比较悲观，认为操作数据的时候，别人同时也会操作数据

具有强烈的排他和独占特性，

对数据被外界修改持有保守态度，

在整个数据处理过程中，将数据处于锁定状态

悲观锁的实现往往依赖数据库提供的锁机制

悲观锁适用于 写操作多的场景，加锁可以保证写数据时数据的正确性

* 乐观锁：乐观锁相较于悲观锁采用了较为宽松的锁机制

大多数基于version版本号实现的。

cas自旋 :内存值、预期值、新值。当且仅当预期值和内存值相等时才将内存值修改为新值 。

应用场景

1.响应速度:如果需要非常高的响应速度，建议采用乐观锁方案

2.如果冲突频率非常高，建议采用悲观锁，保证成功率，如果冲突频率大，乐观锁会需要多次重试才能成功，代价比较大

3.重试代价：如果重试代价大，建议采用悲观锁

务器足够的多，使得缓存对象均匀的分布在服务器上，单台服务器故障，可以防止单台服务器需要抗住2倍流量的情况发生。



Mysql 引擎区别

Innodb 优点：

1.支持事务处理、ACID事务特性；
2.实现了SQL标准的四种隔离级别；
3.支持行级锁和外键约束；
4.可以利用事务日志进行数据恢复。
5.锁级别为行锁，行锁优点是适用于高并发的频繁表修改，高并发是性能优于 MyISAM。缺点是系统消耗较大。
6.索引不仅缓存自身，也缓存数据，相比 MyISAM 需要更大的内存。

缺点：

因为它没有保存表的行数，当使用COUNT统计时会扫描全表。

Myisam 优点：

```
1.高性能读取；

2.因为它保存了表的行数，当使用COUNT统计时不会扫描全表；
```

缺点：

1.锁级别为表锁，表锁优点是开销小，加锁快；缺点是锁粒度大，发生锁冲动概率较高，容纳并发能力低，这个引擎适合查询为主的业务。
2.此引擎不支持事务，也不支持外键。
3.INSERT和UPDATE操作需要锁定整个表；
4.它存储表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。



大表优化

当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：

1. **限定数据的范围：** 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。；

2. **读/写分离：** 经典的数据库拆分方案，主库负责写，从库负责读；

3. **缓存：** 使用MySQL的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存；

4. **垂直分区：**

   **根据数据库里面数据表的相关性进行拆分。** 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

   **简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。** 如下图所示，这样来说大家应该就更容易理解了。

   **垂直拆分的优点：** 可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。

   **垂直拆分的缺点：** 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；

    **5. 水平分区：**

   **保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。**

   水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。

水品拆分可以支持非常大的数据量。需要注意的一点是:分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL 并发能力没有什么意义，所以 **水品拆分最好分库** 。

水平拆分能够 **支持非常大的数据量存储，应用端改造也少**，但 **分片事务难以解决** ，跨界点Join 性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 **尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度** ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络 I/O。



 Hash索引和B+树所有有什么区别或者说优劣呢?**

首先要知道Hash索引和B+树索引的底层实现原理:

hash索引底层就是hash表,进行查找时,调用一次hash函数就可以获取到相应的键值,之后进行回表查询获得实际数据.B+树底层实现是多路平衡查找树.对于每一次的查询都是从根节点出发,查找到叶子节点方可以获得所查键值,然后根据查询判断是否需要回表查询数据.

那么可以看出他们有以下的不同:

- hash索引进行等值查询更快(一般情况下),但是却无法进行范围
- .

因为在hash索引中经过hash函数建立索引之后,索引的顺序与原顺序无法保持一致,不能支持范围查询.而B+树的的所有节点皆遵循(左节点小于父节点,右节点大于父节点,多叉树也类似),天然支持范围.

- hash索引不支持使用索引进行排序,原理同上.
- hash索引不支持模糊查询以及多列索引的最左前缀匹配.原理也是因为hash函数的不可预测.**AAAA**和**AAAAB**的索引没有相关性.
- hash索引任何时候都避免不了回表查询数据,而B+树在符合某些条件(聚簇索引,覆盖索引等)的时候可以只通过索引完成查询.
- hash索引虽然在等值查询上较快,但是不稳定.性能不可预测,当某个键值存在大量重复的时候,发生hash碰撞,此时效率可能极差.而B+树的查询效率比较稳定,对于所有的查询都是从根节点到叶子节点,且树的高度较低.

因此,在大多数情况下,直接选择B+树索引可以获得稳定且较好的查询速度.而不需要使用hash索引.

Redis

### redis内存满了怎么办

1.扩容

2.redis内存淘汰策略，淘汰一些key

volatile-lru 从已**设置过期时间**的数据集中挑选最近**最少使用**的数据淘汰
volatile-ttl 从已设置过期时间的数据集中挑选将**要过期**的数据淘汰
volatile-random从已设置过期时间的数据集中*任意选择数据*淘汰
allkeys-lru从所有数据集中挑选最近**最少使用的数据**淘汰
allkeys-random从所有数据集中任意选择数据进行淘汰
noeviction禁止驱逐数据

3.水平扩容，搭建redis集群

### redis真的是单线程的么

redis负责存储这块是单线程的，

### redis的持久化

有两种持久化机制RDB和AOF

**RDB**

手动触发

- SAVE：阻塞Redis的服务器主进程，直到RDB文件被创建完毕
- BGSAVE：Fork出一个子进程来创建RDB文件，不阻塞服务器进程 `lastsave` 指令可以查看最近的备份时间

自动触发

- 根据redis.conf配置里的save m n定时触发（用的是BGSAVE）(这条自动触发可以关闭例如设置save '')

  服务器再m秒内至少执行了n次修改会自动触发BGSAVE

- 主从复制时，主节点自动触发

- 执行Debug Relaod

- 执行Shutdown且没有开启AOF持久化

**AOF**

记录除了查询以外的所有变更数据库状态的指令

以append的形式追加保存到AOF文件中（增量）

AOF文件越来越大问题

日志重写解决AOF文件不断增大的问题，

瘦身原理如下

- 首先从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录该键值对的多个命令;

redis将aof重写放到子进程中处理，(这样aof重写期间，主进程还能处理操作)，子进程带有主进程的数据副本，这样保障了数据的安全性，但是aof重写期间，主进程还能执行命令，这样导致数据不一致问题，解决的方法，aof重写期间，Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区

**RDB和AOF的优缺点**

RDB优点：全量数据快照，文件小，恢复快

RDB缺点：无法保存最近一次快照之后的数据，数据量大会由于I/O严重影响性能

AOF优点：可读性高，适合保存增量数据，数据不一丢失

AOF缺点：文件体积大，恢复时间长

**RDB-AOF混合持久化方式**

混合持久化过程

混合持久化同样也是通过bgrewriteaof完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本**全量的以RDB方式写入aof文件，然后在将重写缓冲区的增量命令以AOF方式写入到文件**，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。简单的说：新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据，

数据恢复

- aof文件开头是rdb的格式, 先加载 rdb内容再加载剩余的 aof。
- aof文件开头不是rdb的格式，直接以aof格式加载整个文件。

### redis缓存击穿

定义:当一个热点key失效的时候，请求就会直接访问数据库。

解决办法很简单，1.就是访问数据库之前加锁，分布式锁和本地锁都可以，唯一的区别就是后者会多执行几次sql。2.设置热点数据用不失效

具体流程:

1.查询缓存，

2.缓存不存在，加锁 在查询缓存

3.第二次查询缓存不存在，则从数据库拿到该热点key 并更新到缓存返回请求结果，并释放key

解释:加锁之后再查询缓存 ，这一步很关键，比如缓存失效期间有10个请求访问该热点key，但是同一时刻只有一个请求key拿到锁，当这个请求后续业务逻辑处理完成，释放锁之后，后续9个请求从缓存中取的key，从而减少数据库的访问

### redis缓存穿透

定义:当一个请求查询的数据，数据库和缓存都不存在的情况，

解决办法，1存储key对应的空值 ，2布隆过滤器

### redis缓存雪崩

当某一时刻，缓存大面积失效，或则服务器宕机引起

解决办法:

1.搭建高可用集群，

2.设置不一样的缓存过期时间





### 布隆过滤器的原理

### redis为什么那么快

首先redis是内存数据库，读写，随机读写速度远超硬盘

采用了单线程多路复用io阻塞机制，减少了多线程上下文切换带来的花销

cpu利用率会比多线程高

### redis的list实现

redis是双向链表

### redis里面的list,zset的实现原理

zset是通过跳跃表实现的



分布式事务

1.典型的场景就是微服务架构 微服务之间通过远程调用完成事务操作。 比如：订单微服务和库存微服务，下单的 

同时订单微服务请求库存微服务减库存。

2.单体系统访问多个数据库实例 当单体系统需要访问多个数据库（实例）时就会产生分布式事务。

3.多服务访问同一个数据库实例 比如：订单微服务和库存微服务即使访问同一个数据库也会产生分布式事务，原 

因就是跨JVM进程，两个微服务持有了不同的数据库链接进行数据库操作，此时产生分布式事务。



k8s，docker解决了什么问题

Docker:

- 软件更新发布及部署低效，过程繁琐且需要人工介入
- 环境一致性难以保证
- 不同环境之间迁移成本太高

K8s:容器管理

容器，提供应用级的主机抽象；Kubernetes，提供应用级的集群抽象。



聊聊你对领域驱动的看法：

